{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArashKa/keras/blob/master/keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KIvyKmT9R4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Practice on cifar10 data\n",
        " \n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols, img_channels = 32, 32, 3\n",
        "num_classes = 10\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 1\n",
        "\n",
        "# The data, shuffled and split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation='relu',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "datagen = ImageDataGenerator(zca_whitening=True)\n",
        "\n",
        "# Compute principal components required for ZCA\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Apply normalization (ZCA and others)\n",
        "print(x_test.shape)\n",
        "for i in range(len(x_test)):\n",
        "    # this is what you are looking for\n",
        "    x_test[i] = datagen.standardize(x_test[i])\n",
        "print(x_test.shape)\n",
        "\n",
        "# Fit the model on the batches generated by datagen.flow().\n",
        "model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                 batch_size=batch_size),\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}